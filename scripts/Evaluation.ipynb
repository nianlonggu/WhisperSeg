{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ffdfb7-9d76-4a60-a358-d706bc599b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb7f85f-0752-4638-9aa6-17c079ce2fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import WhisperSegmenterFast, WhisperSegmenter\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from train import evaluate\n",
    "from datautils import get_audio_and_label_paths\n",
    "import os\n",
    "from audio_utils import SpecViewer\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fdd2c5-b6cd-4b50-94cf-237120c00006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_dataset( dataset_folder, model_path, num_trials, consolidation_method = \"clustering\",\n",
    "                      max_length = 448, num_beams = 4, batch_size = 8, tolerance = None, spec_time_step = None, eps = None ):\n",
    "    audio_list, label_list = [], []\n",
    "    audio_paths, label_paths = get_audio_and_label_paths(dataset_folder)\n",
    "\n",
    "    # ## debugging\n",
    "    # audio_paths = [item[0] for item in audio_paths ] \n",
    "    \n",
    "    for audio_mc_paths, label_path in zip(audio_paths, label_paths):\n",
    "        label = json.load( open( label_path ) )\n",
    "\n",
    "        audio_mc = []\n",
    "        for audio_path in audio_mc_paths:\n",
    "            audio, _ = librosa.load( audio_path, sr = label[\"sr\"] )\n",
    "            audio_mc.append( audio )\n",
    "        min_len_list = min( [ len(audio) for audio in audio_mc ] )\n",
    "        for c_idx in range(len(audio_mc)):\n",
    "            audio_mc[c_idx] = audio_mc[c_idx][:min_len_list]\n",
    "        audio = np.asarray(audio_mc)\n",
    "        \n",
    "        audio_list.append(audio)\n",
    "        label_list.append(label) \n",
    "        \n",
    "        if tolerance is not None:\n",
    "            label[\"tolerance\"] = tolerance\n",
    "        if spec_time_step is not None:\n",
    "            label[\"spec_time_step\"] = spec_time_step\n",
    "        if eps is not None:\n",
    "            label[\"eps\"] = eps \n",
    "\n",
    "\n",
    "    segmenter = WhisperSegmenterFast(  model_path = model_path,  device = \"cuda\")\n",
    "    res = evaluate( audio_list, label_list, segmenter, batch_size, max_length, num_trials, consolidation_method, num_beams, \n",
    "                    target_cluster = None\n",
    "                  )\n",
    "\n",
    "    all_res = {\n",
    "        \"segment_wise_scores\": {\"N-true-positive\": res[\"segment_wise\"][0],\n",
    "                                \"N-positive-in-prediction\": res[\"segment_wise\"][1],\n",
    "                                \"N-positive-in-ground-truth\": res[\"segment_wise\"][2],\n",
    "                                \"precision\": res[\"segment_wise\"][3],\n",
    "                                \"recall\": res[\"segment_wise\"][4],\n",
    "                                \"F1\": res[\"segment_wise\"][5]\n",
    "                                },\n",
    "        \"frame_wise_scores\": {\"N-true-positive\": res[\"frame_wise\"][0],\n",
    "                                \"N-positive-in-prediction\": res[\"frame_wise\"][1],\n",
    "                                \"N-positive-in-ground-truth\": res[\"frame_wise\"][2],\n",
    "                                \"precision\": res[\"frame_wise\"][3],\n",
    "                                \"recall\": res[\"frame_wise\"][4],\n",
    "                                \"F1\": res[\"frame_wise\"][5]\n",
    "                                }\n",
    "    }\n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c231696-d9b3-4d2d-a287-f40ca170ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:07<00:00, 30.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 835,\n",
       "  'N-positive-in-prediction': 901,\n",
       "  'N-positive-in-ground-truth': 892,\n",
       "  'precision': 0.9267480577136515,\n",
       "  'recall': 0.9360986547085202,\n",
       "  'F1': 0.9313998884551034},\n",
       " 'frame_wise_scores': {'N-true-positive': 78341,\n",
       "  'N-positive-in-prediction': 81184,\n",
       "  'N-positive-in-ground-truth': 83000,\n",
       "  'precision': 0.964980784391013,\n",
       "  'recall': 0.9438674698795181,\n",
       "  'F1': 0.9543073624713736}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/zebra_finch_full/test/\", \n",
    "                 \"../model/mc-whisperseg-mc-zebra-finch-mask-08-2_5-5epochs/final_checkpoint_ct2/\", \n",
    "                  num_trials = 3, tolerance = 0.02 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c6815-4976-4156-81b2-ad262428a35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a11e645-9abe-4664-ab1a-562f4583af55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import WhisperSegmenterFast, WhisperSegmenter\n",
    "from audio_utils import SpecViewer\n",
    "# segmenter = WhisperSegmenterFast( \"../model/mc-whisperseg-mc-zebra-finch-mask-08-2_5-5epochs/final_checkpoint_ct2/\", device=\"cuda\" )\n",
    "segmenter = WhisperSegmenterFast( \"nccratliri/mc-whisperseg-zebra-finch-ct2-v1.0\", device=\"cuda\" )\n",
    "spec_viewer = SpecViewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d579645b-55df-49de-9bd2-4f19c5cb0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_pattern = \"../data/datasets/zebra_finch_full/test/BP_2021-05-23_09-22-46_918470_0580000_radio2_as_target_channel_*.wav\" \n",
    "\n",
    "audio_fname_list = sorted(glob( audio_file_pattern ), key = lambda x:int(x.split(\"_\")[-1].split(\".wav\")[0]))\n",
    "label_fname = audio_fname_list[0][:-4] + \".json\"\n",
    "label = json.load(open(label_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edaa2b4f-458c-4883-8dfa-c323edd2da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = label[\"sr\"]  \n",
    "min_frequency = label[\"min_frequency\"]\n",
    "spec_time_step = label[\"spec_time_step\"]\n",
    "min_segment_length = label[\"min_segment_length\"]\n",
    "eps = label[\"eps\"]\n",
    "num_trials = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2df54b61-5486-4f87-96de-a0c7d67d7dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_list = []\n",
    "for audio_fname in audio_fname_list:\n",
    "    audio, _ = librosa.load( audio_fname, sr = sr )\n",
    "    audio_list.append(  audio )\n",
    "\n",
    "audio = np.asarray(audio_list)\n",
    "\n",
    "prediction = segmenter.segment(  audio, sr = sr, min_frequency = min_frequency, spec_time_step = spec_time_step,\n",
    "                       min_segment_length = min_segment_length, eps = eps,num_trials = num_trials, batch_size=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ee830dc-0e4c-40ea-9b82-4ad86b19b89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 88, 86, 0.8863636363636364, 0.9069767441860465, 0.896551724137931)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmenter.segment_score( prediction, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9905f7fa-403c-4f37-af96-50e5021ec544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7fe513607d4d9bb979ed9338599e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=207.0, description='offset', max=414.4304375, step=0.25), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_viewer.visualize( audio = audio, sr = sr, min_frequency= min_frequency, prediction = prediction, label=label, \n",
    "                       window_size=5, precision_bits=1, \n",
    "                       audio_channel_names=[\"Mic\", \"non-target\\nradio\", \"target\\nradio\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc668bd0-6f67-47bc-825a-398aa80e4494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09293f2b-153b-4ef3-a994-18651d6bff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_utils import SpecViewer\n",
    "import librosa\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json\n",
    "from model import MultiChannelWhisperSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d110e384-97fd-42de-bb08-39166f488b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_segmenter = MultiChannelWhisperSeg( \"nccratliri/mc-whisperseg-zebra-finch-ct2-v1.0\", device=\"cuda\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9d9a6a-1417-4d94-bff6-d41d4e818c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "## There should be at least 1 radio channel, and at least 1 mic channel. \n",
    "## The number of radio channels can be greater than 2\n",
    "radio_fname_list = [ \n",
    "     \"../data/example_subset/Zebra_finch/test/BP_2021-05-23_09-22-46_918470_0580000_radio1.wav\",\n",
    "     \"../data/example_subset/Zebra_finch/test/BP_2021-05-23_09-22-46_918470_0580000_radio2.wav\"\n",
    "]\n",
    "mic_fname_list = [\n",
    "     \"../data/example_subset/Zebra_finch/test/BP_2021-05-23_09-22-46_918470_0580000_daq1.wav\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965d73da-6ebf-4a8e-9aac-903a768037a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_channels = [ librosa.load( fname, sr = sr )[0] for fname in radio_fname_list ]\n",
    "mic_channels = [ librosa.load( fname, sr = sr )[0] for fname in mic_fname_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356a8cb2-552e-461d-a50e-fa1188931f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting radio channel 0 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] 100.00%\n",
      "Segmenting radio channel 1 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] 100.00%\n"
     ]
    }
   ],
   "source": [
    "predictions = mc_segmenter.segment( radio_channels, mic_channels, sr,\n",
    "                      min_frequency = 0,\n",
    "                      spec_time_step = 0.0025,\n",
    "                      min_segment_length = 0.005,\n",
    "                      eps = 0.02,\n",
    "                      num_trials = 3\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44655d07-4fa1-4395-af41-afccfa860083",
   "metadata": {},
   "source": [
    "predictions is a list of prediction. Each prediction corresponds to one radio channel. For example, predictions[0] contains the segmentation results of radio_channels[0].\n",
    "\n",
    "predictions[0] is a dictionary containing \"onset\", \"offset\" and \"cluster\" as usual.\n",
    "\n",
    "Let's visualize the segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8175aac9-67ed-4175-a804-6170477f6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_viewer = SpecViewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc6acb5-3954-4609-aa94-16e45b5ca3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment-F1: 0.9692307692307693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9cd290d93f49c6be9ea15e62b086a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=207.0, description='offset', max=414.4304375, step=0.25), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" suppose radio1 is the target channel we are segmenting now,\n",
    "    predictions[0] contains the segmentation results of radio1\"\"\"\n",
    "## load the ground-truth segmentation:\n",
    "label_radio1 = json.load(open(\"../data/example_subset/Zebra_finch/test/BP_2021-05-23_09-22-46_918470_0580000_radio1.json\"))\n",
    "## compute score\n",
    "segment_score = mc_segmenter.segmenter.segment_score( prediction = predictions[0], label = label_radio1 )\n",
    "print(\"segment-F1:\",segment_score[-1])\n",
    "## visualize\n",
    "spec_viewer.visualize(\n",
    "    np.asarray([ radio_channels[0], radio_channels[1], mic_channels[0] ]),\n",
    "    sr = sr,\n",
    "    label = label_radio1,\n",
    "    prediction= predictions[0],\n",
    "    audio_channel_names=[\"Mic (daq1)\", \"radio 2\", \"radio 1\\n(target)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c641589c-23a7-48bd-857c-79da6842719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment-F1: 0.896551724137931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d503c9eb2094f0e9eecb1118509ac06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=207.0, description='offset', max=414.4304375, step=0.25), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" suppose radio2 is the target channel we are segmenting now,\n",
    "    predictions[1] contains the segmentation results of radio2\"\"\"\n",
    "## load the ground-truth segmentation:\n",
    "label_radio2 = json.load(open(\"../data/example_subset/Zebra_finch/test/BP_2021-05-23_09-22-46_918470_0580000_radio2.json\"))\n",
    "## compute score\n",
    "segment_score = mc_segmenter.segmenter.segment_score( prediction = predictions[1], label = label_radio2 )\n",
    "print(\"segment-F1:\",segment_score[-1])\n",
    "## visualize\n",
    "spec_viewer.visualize(\n",
    "    np.asarray([ radio_channels[0], radio_channels[1], mic_channels[0] ]),\n",
    "    sr = sr,\n",
    "    label = label_radio2,\n",
    "    prediction= predictions[1],\n",
    "    audio_channel_names=[\"Mic (daq1)\", \"radio 2\\n(target)\", \"radio 1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ada02e-1e18-4068-8253-d339847e66c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wseg]",
   "language": "python",
   "name": "conda-env-wseg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
