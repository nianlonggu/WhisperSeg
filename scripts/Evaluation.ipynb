{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c427f5b3-889f-4ffe-84f7-5f43bc264a0b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ffdfb7-9d76-4a60-a358-d706bc599b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb7f85f-0752-4638-9aa6-17c079ce2fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import WhisperSegmenterFast, WhisperSegmenter\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from train import evaluate\n",
    "from datautils import get_audio_and_label_paths\n",
    "import os\n",
    "from audio_utils import SpecViewer\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fdd2c5-b6cd-4b50-94cf-237120c00006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_dataset( dataset_folder, model_path, num_trials, consolidation_method = \"clustering\",\n",
    "                      max_length = 448, num_beams = 4, batch_size = 8, tolerance = None, spec_time_step = None, eps = None ):\n",
    "    audio_list, label_list = [], []\n",
    "    audio_paths, label_paths = get_audio_and_label_paths(dataset_folder)\n",
    "    for audio_path, label_path in zip(audio_paths, label_paths):\n",
    "        label = json.load( open( label_path ) )\n",
    "        audio, _ = librosa.load( audio_path, sr = label[\"sr\"] )\n",
    "        audio_list.append(audio)\n",
    "        label_list.append(label) \n",
    "        \n",
    "        if tolerance is not None:\n",
    "            label[\"tolerance\"] = tolerance\n",
    "        if spec_time_step is not None:\n",
    "            label[\"spec_time_step\"] = spec_time_step\n",
    "        if eps is not None:\n",
    "            label[\"eps\"] = eps \n",
    "\n",
    "\n",
    "    segmenter = WhisperSegmenterFast(  model_path = model_path,  device = \"cuda\")\n",
    "    res = evaluate( audio_list, label_list, segmenter, batch_size, max_length, num_trials, consolidation_method, num_beams, \n",
    "                    target_cluster = None\n",
    "                  )\n",
    "\n",
    "    all_res = {\n",
    "        \"segment_wise_scores\": {\"N-true-positive\": res[\"segment_wise\"][0],\n",
    "                                \"N-positive-in-prediction\": res[\"segment_wise\"][1],\n",
    "                                \"N-positive-in-ground-truth\": res[\"segment_wise\"][2],\n",
    "                                \"precision\": res[\"segment_wise\"][3],\n",
    "                                \"recall\": res[\"segment_wise\"][4],\n",
    "                                \"F1\": res[\"segment_wise\"][5]\n",
    "                                },\n",
    "        \"frame_wise_scores\": {\"N-true-positive\": res[\"frame_wise\"][0],\n",
    "                                \"N-positive-in-prediction\": res[\"frame_wise\"][1],\n",
    "                                \"N-positive-in-ground-truth\": res[\"frame_wise\"][2],\n",
    "                                \"precision\": res[\"frame_wise\"][3],\n",
    "                                \"recall\": res[\"frame_wise\"][4],\n",
    "                                \"F1\": res[\"frame_wise\"][5]\n",
    "                                }\n",
    "    }\n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4afcda1d-79ec-4d1d-ae97-d42dee94e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 674/674 [03:22<00:00,  3.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 7725,\n",
       "  'N-positive-in-prediction': 8003,\n",
       "  'N-positive-in-ground-truth': 7987,\n",
       "  'precision': 0.9652630263651131,\n",
       "  'recall': 0.9671966946287718,\n",
       "  'F1': 0.9662288930581615},\n",
       " 'frame_wise_scores': {'N-true-positive': 963293,\n",
       "  'N-positive-in-prediction': 994371,\n",
       "  'N-positive-in-ground-truth': 983355,\n",
       "  'precision': 0.968746071637246,\n",
       "  'recall': 0.9795984156281302,\n",
       "  'F1': 0.9741420196730993}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/multi_species_data/data/multi-species/test/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 1, tolerance = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2d28a6-405a-4627-8189-883b123590c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 7/7 [01:25<00:00, 12.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 579,\n",
       "  'N-positive-in-prediction': 709,\n",
       "  'N-positive-in-ground-truth': 702,\n",
       "  'precision': 0.8166431593794076,\n",
       "  'recall': 0.8247863247863247,\n",
       "  'F1': 0.8206945428773919},\n",
       " 'frame_wise_scores': {'N-true-positive': 69959,\n",
       "  'N-positive-in-prediction': 79660,\n",
       "  'N-positive-in-ground-truth': 75877,\n",
       "  'precision': 0.8782199347225709,\n",
       "  'recall': 0.922005350765054,\n",
       "  'F1': 0.8995801642053016}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/marmoset/test/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 3, tolerance = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a8457f4-d7e9-4161-8e56-0cbd2178e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 3/3 [00:25<00:00,  8.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 213,\n",
       "  'N-positive-in-prediction': 216,\n",
       "  'N-positive-in-ground-truth': 229,\n",
       "  'precision': 0.9861111111111112,\n",
       "  'recall': 0.9301310043668122,\n",
       "  'F1': 0.957303370786517},\n",
       " 'frame_wise_scores': {'N-true-positive': 10621,\n",
       "  'N-positive-in-prediction': 10774,\n",
       "  'N-positive-in-ground-truth': 10852,\n",
       "  'precision': 0.9857991460924448,\n",
       "  'recall': 0.9787136011795061,\n",
       "  'F1': 0.9822435956718765}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/mouse/test/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 3, tolerance = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f0ecaf9-5bd3-4235-8906-99ae0ee5ab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 27,\n",
       "  'N-positive-in-prediction': 74,\n",
       "  'N-positive-in-ground-truth': 93,\n",
       "  'precision': 0.36486486486486486,\n",
       "  'recall': 0.2903225806451613,\n",
       "  'F1': 0.32335329341317365},\n",
       " 'frame_wise_scores': {'N-true-positive': 31059,\n",
       "  'N-positive-in-prediction': 34378,\n",
       "  'N-positive-in-ground-truth': 32231,\n",
       "  'precision': 0.903455698411775,\n",
       "  'recall': 0.9636374918556669,\n",
       "  'F1': 0.9325766788271854}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/human/test/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 1, tolerance = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7452dff-c73c-469b-8917-a6f788c8b739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 84/84 [01:03<00:00,  1.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 943,\n",
       "  'N-positive-in-prediction': 990,\n",
       "  'N-positive-in-ground-truth': 980,\n",
       "  'precision': 0.9525252525252526,\n",
       "  'recall': 0.9622448979591837,\n",
       "  'F1': 0.9573604060913707},\n",
       " 'frame_wise_scores': {'N-true-positive': 128640,\n",
       "  'N-positive-in-prediction': 131043,\n",
       "  'N-positive-in-ground-truth': 130616,\n",
       "  'precision': 0.9816625077264715,\n",
       "  'recall': 0.984871684939058,\n",
       "  'F1': 0.9832644778127256}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/zebra_finch/test_juveniles/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 3, tolerance = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "045c8058-9373-4d5f-abf7-b08512c5518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 199/199 [02:25<00:00,  1.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 3895,\n",
       "  'N-positive-in-prediction': 3907,\n",
       "  'N-positive-in-ground-truth': 3909,\n",
       "  'precision': 0.9969285897107756,\n",
       "  'recall': 0.9964185213609619,\n",
       "  'F1': 0.9966734902763562},\n",
       " 'frame_wise_scores': {'N-true-positive': 588620,\n",
       "  'N-positive-in-prediction': 594305,\n",
       "  'N-positive-in-ground-truth': 594148,\n",
       "  'precision': 0.9904342046592238,\n",
       "  'recall': 0.9906959208816658,\n",
       "  'F1': 0.9905650454834982}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/zebra_finch/test_adults/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 3, tolerance = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d61b20e-f1b0-41f9-a773-eb6901ea1132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 379/379 [01:45<00:00,  3.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 2035,\n",
       "  'N-positive-in-prediction': 2077,\n",
       "  'N-positive-in-ground-truth': 2074,\n",
       "  'precision': 0.9797785267212326,\n",
       "  'recall': 0.9811957569913211,\n",
       "  'F1': 0.9804866297277763},\n",
       " 'frame_wise_scores': {'N-true-positive': 137038,\n",
       "  'N-positive-in-prediction': 141645,\n",
       "  'N-positive-in-ground-truth': 139631,\n",
       "  'precision': 0.9674750255921494,\n",
       "  'recall': 0.9814296252264898,\n",
       "  'F1': 0.974402366359021}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/bengalese_finch/test/\", \n",
    "                 \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", \n",
    "                  num_trials = 3, tolerance = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225ddd2-905e-4142-8e12-ef74c4a16857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "719bb28a-228b-4543-ad2c-a49d472bcf0c",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a11e645-9abe-4664-ab1a-562f4583af55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32af603ad4e2429eb1ed07a4bd8aab64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c65733474a142a180900ba82ea11bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4fbfe2ce5e4a16a493ea48380ed0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff7a52cea774df6b9a3a40597d1c73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b6f3cc63e24901a2a735b2a053034b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a794a41b0b4ac4a1ed56ecec0f0579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc205b438314b178f96f0174cf02733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d85888b32d8495b8be0bd82d46e6c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36859438d4ea47e6bf5b7458915625e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model import WhisperSegmenterFast, WhisperSegmenter\n",
    "from audio_utils import SpecViewer\n",
    "# segmenter = WhisperSegmenterFast( \"../model/whisperseg-large-vad-v0.1/final_checkpoint_ct2/\", device=\"cuda\" )\n",
    "segmenter = WhisperSegmenter( \"nccratliri/whisperseg-large-vad-v1.0\", device=\"cuda\" )\n",
    "spec_viewer = SpecViewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f120142-10a3-4c8c-94c8-3c4af051df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"../data/datasets/multi_species_data/data/multi-species/test/bengalese_finch_bl26lb16_190412_0721.20144_0.wav\"\n",
    "label_file = audio_file[:-4] + \".json\"\n",
    "data = json.load(open(label_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df54b61-5486-4f87-96de-a0c7d67d7dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8247ee2e8d39488694efef294d3fda95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='offset', max=0.0, step=0.25), Output()), _dom_classe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = data[\"sr\"]  \n",
    "min_frequency = data[\"min_frequency\"]\n",
    "spec_time_step = data[\"spec_time_step\"]\n",
    "min_segment_length = data[\"min_segment_length\"]\n",
    "eps = data[\"eps\"]\n",
    "num_trials = 1\n",
    "\n",
    "audio, _ = librosa.load( audio_file, sr = sr )\n",
    "label = json.load( open(label_file) )\n",
    "\n",
    "prediction = segmenter.segment(  audio, sr = sr, min_frequency = min_frequency, spec_time_step = spec_time_step,\n",
    "                       min_segment_length = min_segment_length, eps = eps,num_trials = num_trials, batch_size=4 )\n",
    "spec_viewer.visualize( audio = audio, sr = sr, min_frequency= min_frequency, prediction = prediction, label=label, \n",
    "                       window_size=5, precision_bits=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92976494-803c-4a79-a7b6-b7a0dd433882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
